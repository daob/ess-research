\documentclass[a4paper,12pt]{article}
\usepackage{fullpage}
\usepackage{ucs}
\usepackage{graphicx}
\usepackage{apalike}
\usepackage{longtable}
\usepackage{hyperref}
\bibliographystyle{apalike}
 \input epsf
\author{Willem E. Saris\\Daniel Oberski\\ESADE, Universitat Ramon Llull\\\\Jacques Hagenaars\\Tilburg University}

\title{Categorisation errors and differences in the quality of questions across countries}


\begin{document}
\maketitle
\begin{abstract}
The European Social Survey (ESS) has the unique characteristic that in more than 20 countries the same questions are asked and that within each round of the ESS Multitrait-Multimethod (MTMM) experiments are built in to evaluate the quality of a limited number of questions. This gives us an exceptional opportunity to observe the differences in quality of questions over a large number of countries. The MTMM experiments make it possible to estimate the reliability, validity and method effects of single questions \cite{andrews_construct_1984,saris_new_2004,saris_evaluation_1991}. The product of the reliability and the validity can be interpreted as the explained variance in the observed variable by the variable one would like to measure. It is a measure of the total quality of a question.

These MTMM experiments showed that there are considerable differences in measurement quality across countries. Because these differences in quality can cause wrong conclusions with respect to differences in relationships across countries this paper studies several reasons for these differences.
\end{abstract}\newpage

\section*{Introduction}

Measurement error can invalidate conclusions drawn from cross-country comparisons if the errors differ from country to country \cite{Saris_design_2007}. For this reason, when different groups such as countries as compared with one another, attention should not only be given to absolute levels of errors, but also to the differences between the groups. Different strategies have been developed to deal with the problem, for example within the context of invariance testing in the social sciences \cite{joreskog_simultaneous_1971}, differential item function in psychology \cite{muthen_multiple_1985}, and differential measurement error models in epidemiology and biostatistics \cite{carroll_nonlinear_1995}.

In the ESS a lot of time, money, and effort is spent to make the questions as functionally equivalent across countries as possible \cite{harkness_cross-cultural_2002} and to make the samples as comparable as possible (H\"{a}der and Lynn 2007)*. Nevertheless, considerable differences in quality of the questions can be observed across countries (see Table \ref{tab:countries}). In round 2 of the ESS the largest difference found was between questions in Sweden with a quality of .4 and in Portugal with a quality above .9. The Scandinavian countries had an average quality around .5 over 54 questions while other countries such as Greece, Portugal and Estonia had an average quality of .8.  To study these differences is important because these differences can cause differences in relationships between variables in different countries which have no substantive meaning but are just caused by differences in quality in the measurement \cite{Saris_design_2007}. In order to avoid such differences it is also important to study reasons for these differences in quality. 

In an earlier study, we investigated differences in translations, differences in the experiments' design, and differences in the complexity of the question as possible reasons for differences in question quality across countries \cite{oberski_differences_}. Here we consider differences in categorisation errors or use of the answer scale as a source of differences between countries. 

First we provide the necessary background: the response model we use as our starting point, and explanations of the multitrait-multimethod (MTMM) experiments we use to assess question quality  and of categorisation error. Next we give a short overview of our limited previous findings on the origins of cross-country differences in measurement error. We then present the data from the European Social Survey and the structure of the experiments, and discuss the methods used to analyse these data. The subsequent section describes our analysis of categorisation errors for four experiments using categorical scales, and ends with a meta-analysis of these results. We then summarise and discuss our findings. Finally, some general conclusions are drawn and suggestions for further research are indicated.

\section{Background}

In Figure \ref{fig:response} we show the basic response model \cite{Saris_design_2007} we use as our starting point. 

\begin{figure}[bh]
%\epsffile{response-model.eps}
\caption{The response model used in the MTMM experiments.\label{fig:response}}
\end{figure}

The difference between the observed response ($y$) and the so called `true score' ($t$) is random measurement error ($e$). So the coefficient $r$ represents the reliability coefficient and $r^2$ is the reliability.
The difference between the true score and the concept by intuition ($f_1$) are the respondents' systematic reactions to the method ($m$). So the coefficient $v$ represents the true score validity coefficient and $v^2$ is the true score validity. The quality of a measure ($q^2$) is defined as  $q^2 =  r^2 . v^2$ and $q$ is the quality coefficient. The correlation between the unobserved variables of interest is denoted by $\rho(f_1,f_2)$.
Several remarks should be made. The first is that the correlation $\rho(y_i, y_j)$ between two observed variables is:
\begin{equation}
\rho(y_i, y_j) = \overbrace{\rho(f_i, f_j)}^{\textrm{Correlation of interest}} \cdot \overbrace{q_i \cdot q_j}^{\textrm{Attenuation factor}} + \overbrace{r_i \cdot r_j \cdot m_i \cdot m_j}^{\textrm{Correlation due to method}}
\label{eqn:attenuation}\end{equation}
This means that the correlation between the observed variables is normally smaller than the correlation between the variables of interest, but can be larger if the method effects are considerable. A second remark to make is that one can not compare correlations across countries without correction for measurement error if the measurement quality coefficients are very different across countries: this follows directly from the above equation (\ref{eqn:attenuation}). A third point is that one can not estimate these quality indicators from this simple design with two observed variables. In this model there are two reliability coefficients, two validity coefficients, two method effects and one correlation between the two latent traits, leaving us with seven unknown parameters, while only one correlation can be obtained from the data. It is impossible to estimate these seven parameters from just one correlation.  

There are two different approaches to estimate these coefficients. The first is the use of MTMM experiments. The second is the use of the prediction program SQP that is based on a large number of MTMM experiments \cite{oberski_sqp_}. Because we use the MTMM approach here, it is briefly introduced below. A more elaborate introduction to MTMM and SQP can be found in Saris and Gallhofer (2007).

\subsection{MTMM models}

Campbell and Fiske (1959) suggested using multiple traits and multiple methods (MTMM). The classical MTMM approach recommends the use of a minimum of three traits that are measured with three different methods leading to nine different observed variables. An example of such a design is given in Table \ref{tab:design}.  

\begin{table}[htb]\caption{The classic MTMM design used in the ESS pilot study.\label{tab:design}}
\fbox{\begin{minipage}{\textwidth}
The three traits were presented by the following three requests:
\begin{itemize}
\item \textit{On the whole, how satisfied are you with the present state of the economy in Britain?}
\item \textit{Now think about the national government. How satisfied are you with the way it is doing its job?}
\item \textit{And on the whole, how satisfied are you with the way democracy works in Britain?} 
\end{itemize}

The three methods are specified by the following response scales: 
\begin{quote}
\textit{(1) Very satisfied; (2) Fairly satisfied; (3) Fairly dissatisfied; (4) Very dissatisfied}  
\begin{tabular}{ccccccccccc}
\textit{Very dissatisfied		}&&&&&&&&&&			        \textit{Very satisfied}\\
		       0 &    1&     2 &    3&     4     &5     &6     &7     &8     &9     &10\\
\end{tabular}

\textit{(1) Not at all satisfied; (2) Satisfied;  (3) Rather satisfied;  (4) Very satisfied}
\end{quote}\end{minipage}}
\end{table}

Collecting data using this MTMM design, data for nine variables are obtained and from that data a correlation matrix of $9 \times 9$ is obtained. The model formulated to estimate the reliability, validity, and method effects is an extension of the model presented in Figure \ref{fig:response}. This figure illustrates the relationships between the true scores and their general factors of interest. Figure \ref{fig:mtmm} shows that each trait ($f_i$) is measured in three ways. It is assumed that the traits are correlated but that the method factors ($M_1$, $M_2$, $M_3$) are not correlated. To reduce the complexity of the figure, it is not indicated that for each true score there is an observed response variable that is affected by the true score and a random error as was previously introduced in the model in Figure \ref{fig:response}. However, these relationships, although not made explicit, are implied.  

\begin{figure}[htb]\caption{\label{fig:mtmm}MTMM model illustrating the true scores and their factors of interest.}
figure about here
\end{figure}
 
The MTMM design of 3 traits and 3 methods generates 45 covariances and variances. In turn, these 45 pieces of information provide sufficient information to estimate 9 reliability and 9 validity coefficients, 3 method effect coefficients and 3 correlations between the traits. In total there are 24 parameters to be estimated. This leaves 45 ─ 24 = 21 degrees of freedom, meaning that the necessary condition for identification is fulfilled. It also can be shown that the sufficient condition for identification is satisfied and given that $df=21$ a test of the model is possible.

Table \ref{tab:mtmm_cor} presents the correlations that we derived between the 9 measures obtained from a sample of 481 people in the British population. Using the specifications of the model indicated above and the ML estimator to estimate the quality indicators, the results presented in Table \ref{tab:mtmm_results} are obtained\footnote{In this case the ML estimator is used. The estimation is done using the covariance matrix as the input matrix and not the correlation matrix . Thereafter, the estimates are standardized to obtain the requested coefficients. A result of this is that the standardized  method effects are not exactly equal to each other.}.  

\begin{table}\centering\caption{Correlations between nine measures obtained from a sample of 481 people from the British population. Correlations between a repetition of a trait using a different method (`monotrait-heteromethod' correlations) are indicated in boldface.\label{tab:mtmm_cor}}
\begin{tabular}{lrrrrrrrrr}\hline
& \multicolumn{3}{c}{Method 1} & \multicolumn{3}{c}{Method 2} & \multicolumn{3}{c}{Method  3} \\ 
\hline
& Q1 & Q2 & Q3 & Q1 & Q2 & Q3 & Q1 & Q2 & Q3 \\ 
Method 1\\ 
Q1 & 1.00 \\ 
Q2 & .481 & 1.00 &  \\ 
Q3 & .373 & .552 & 1.00 \\ 
Method 2\\ 
Q1 & \textbf{-.626} & -.422 & -.410 & 1.00 \\ 
Q2 & -.429 & \textbf{-.663} & -.532 & .642 & 1.00 \\ 
Q3 & -.453 & -.495 & -\textbf{.669} & .612 & .693 & 1.00 \\ 
Method 3\\
Q1 & -\textbf{.502} & -.374 & -.332 & .\textbf{584} & .436 & .438 & 1.00 \\ 
Q2 & -.370 & -\textbf{.608} & -.399 & .429 & .\textbf{653} & .466 & .556 & 1.00 \\ 
Q3 & -.336 & -.406 & -\textbf{.566} & .406 & .471 & .\textbf{638} & .514 & .558 & 1.00 \\ 
 \\ 
Mean & 2.42 & 2.71 & 2.45 & 5.26 & 4.37 & 5.13 & 2.01 & 1.75 & 2.01 \\ 
Standard Deviation & .77 & .76 & .84 & 2.29 & 2.37 & 2.44 & .72 & .71 & .77 \\ 
\hline
\end{tabular}

\end{table}


\begin{table}\centering\caption{The standardised estimates of the MTMM parameters (figure \ref{fig:mtmm}), which are obtained when analysing the sample covariance matrix above.\label{tab:mtmm_results}}
\begin{tabular}{lrrrrrrrr}\hline
 &   \multicolumn{3}{c}{Validity coeffs} & \multicolumn{3}{c}{Method effects} &  & Reliability coeff.\\ 
 \hline
    & F1 & F2 & F3 & M1 & M2 & M3 \\ 
T11   & .93 &  &  & .36 &  &  &  & .79 \\ 
T21   &  & .94 &  & .35 &  &  &  & .85 \\ 
T31   &  &  & .95 & .33 &  &  &  & .81 \\ 
 \\ 
T12   & .91 &  &  &  & .41 &  &  & .91 \\ 
T22   &  & .92 &  &  & .39 &  &  & .94     \\ 
T32   &  &  & .93 &  & .38 &  &  & .93 \\ 
 \\ 
T13   & .85 &  &  &  &  & .52 &  & .82 \\ 
T23   &  & .87 &  &  &  & .50 &  & .87\\ 
T33   &  &  & .88 &  &  & .48 &  & .84  \\
\hline
\end{tabular}
\end{table}

\subsection{The categorical response model}

The response model discussed so far makes no mention of the fact that many of the measures we use are in fact ordinal--that is, they are ordered categories rather than a continuous scale. 
Broadly speaking, two types of measurement models have been proposed for this situation. The first assumes there is an unobserved categorical variable, and that errors arise from the conditional chances of choosing a category on the survey question given the unobserved score. Such models are often referred to as latent class models or finite mixture models \cite{lazarsfeld_latent_1968}.

The second approach deals with the case where a continuous scale or `latent response variable' is thought to underly the observed categorical item. Such models are sometimes called latent trait models. Several possible extensions are possible, but we focus on a special case described by Muth\'en (1978). This is the model we will use in our subsequent analysis of the data.

Errors may arise at two stages. The first is the connection between the latent response variable and its latent trait. This part of the error model is completely analagous to factor analysis or MTMM models for continuous data: the scale is modelled as a linear combination of a latent trait, a reaction to the particular method used to measure the trait, and a random error, and interest then focuses on the connection between the trait and the scale, which we again term the `quality coefficient' (see figure \ref{fig:mtmm}). 

The second stage at which errors arise, however, differs from the continuous case. Here the continuous latent response variable is split up into the different categories, such that each category of the observed variable corresponds to a certain range on the unobserved continuous scale. The sizes of these ranges are determined by threshold parameters.

Thus, the model we use allows to a certain extent the separation of errors due to the categorisation, errors due to the method and random errors. We will use this fact later on to compare the amount of error due to categorisation introduced across countries.

It can be shown that analysing polychoric correlations in an MTMM model is a special case of the model we use (Muth\'{e}n \& Asparouhov, 2002). However, we do not use polychoric correlations because it would be  necessary to assume that the variances of the latent response variables are equal across countries. Since we try to separate categorisation errors from differences in the continuous part of the model, this is not a desirable assumption. Last, it should be noted that the model we use is equivalent to a multi-dimensional two parameter graded response model in item response theory (Muth\'{e}n \& Asparouhov, 2002).


\section{Data}


The European Social Survey (ESS) has the unique characteristic that in more than 20 countries the same questions were asked and that within each round of the ESS Multitrait-Multimethod (MTMM) experiments are built in to evaluate the quality of a limited number of questions. This gives us an exceptional opportunity to observe the differences in quality of questions over a large number of countries. In this paper we have used the MTMM experiments of round 2 of the ESS. The topics of the 6 MTMM experiments in the second round of the ESS were the following:
\begin{enumerate}
\item Time spent on housework;
\item The social distance between the doctor and patients;
\item Opinions about job;
\item The role of men and women in society;
\item Satisfaction with the political situation;
\item Political trust.
\end{enumerate}
Concerning each of these topics 3 questions were asked and these three questions were presented in 3 different forms following the discussed MTMM designs 
\cite{campbell_convergent_1959}. The first form,  used for all respondents, was presented in the main questionnaire. The two alternative forms were presented in a supplementary questionnaire which was filled in after the main questionnaire. All respondents were only asked to reply to one alternative form but different groups got different version of the same questions \cite{saris_new_2004}. For the specific questions for the 6 experiments we refer to the ESS website where the English source version of all questions are presented\footnote{http://www.europeansocialsurvey.org}, and for the different translations we refer to the ESS archive\footnote{http://ess.nsd.uib.no}.

	Each experiment varies a different aspect of the method by which questions can be asked in questionnaires. The `housework' experiment compares numeric estimates by respondents with other scales. The `doctors' experiment examines the effect of choosing arbitrary scale positions as a starting point for agreement-disagreement with a statement. The `job' experiment compares a 4 point with an 11 point scale and a true-false scale with a direct question. In the `women' experiment agree-disagree scales are reversed, there is one negative item, and a `don't know' category is omitted in one of the methods.  The `satisfaction' experiment varies the extremeness and number of fixed reference points of the scale. And finally, the experiment on political trust was meant to investigate the effect of repeating the same question in the same format.

A special group took care that the samples in the different countries where proper probability samples and as comparable as possible (H\"{a}der and Lynn 2007). 

The questions asked in the different countries have been translated from the English source questionnaire. An optimal effort has been made to make these questions as equivalent as possible and to avoid errors. In order to reach this goal two translators independently translated the source questionnaire and a third person was involved to choose the optimal translation by consensus if differences were found. For details of this procedure we refer to the work of Harkness (2007).

	 Despite these efforts to make the data as comparable as possible, big differences in measurement quality were found across the different countries.  Table \ref{tab:countries} shows the mean and median standardised quality of the questions in the main questionnaire across the experiments for the different countries.

\begin{table}[hbt]\centering\caption{The quality of all 18 questions included in the experiments in the main questionnaire.\label{tab:countries}}
\begin{tabular}{lrrrr}
\hline
Country&Mean&Median&Minimum&Maximum\\\hline
Portugal&0.79&0.81&0.63&0.91\\
Switzerland&0.79&0.84&0.56&0.90\\
Greece&0.78&0.79&0.64&0.90\\
Estonia&0.78&0.85&0.58&0.90\\
Poland&0.73&0.85&0.51&0.90\\
Luxembourg&0.72&0.73&0.53&0.88\\
United Kingdom&0.70&0.71&0.56&0.82\\
Denmark&0.70&0.70&0.52&0.80\\
Belgium&0.70&0.73&0.46&0.90\\
Germany&0.69&0.70&0.53&0.83\\
Spain&0.69&0.64&0.54&0.90\\
Austria&0.68&0.68&0.51&0.85\\
Czech Republic&0.65&0.60&0.52&0.87\\
Slovenia&0.63&0.60&0.46&0.82\\
Norway&0.59&0.59&0.35&0.83\\
Sweden&0.58&0.58&0.43&0.68\\
Finland&0.57&0.54&0.42&0.78\\
	\hline
\end{tabular}
\end{table}

A remarkable phenomenon in this table is that the Scandinavian countries have the lowest quality of all while the highest quality has been obtained in Portugal, Switzerland, Greece, and Estonia. The other countries are in between these two groups. 
The differences are considerable and statistically significant across countries ($F=3.19$, $df=16$, $p<.001$) and experiments ($F=92.65$, $df=5$, $p<.0001$)\footnote{The significance of the differences in the quality coefficients was determined using their observed distribution.}. The highest mean quality is .79 in Portugal while the lowest is .57 in Finland. If the correlation between the constructs of interest is .6 in both countries and the measures for these variables have the above quality then the observed correlation in Portugal would be .474 while the observed correlation in Finland would be .342. Most people would say that this is a large difference in correlations which requires a substantive explanation. But this difference can be expected because of differences in data quality and has no substantive meaning at all.

\section{Explanations for cross-country differences in question quality}

The previous section showed that in some cases large differences were found in question quality across the countries of the ESS. In a previous study, we examined different explanations of these discrepancies.


\section{Methods}


\section{Results}

We first turn to the hypothesis that all thresholds are equal across different countries. We selected the three countries with the highest and the two countries with the lowest quality coefficients for the `women' experiment. In this experiment wording of the question reversed in the second method. For example, the statement `When jobs are scarce, men should have more right to a job than women' from the main questionnaire was changed to `When jobs are scarce, women should have the same right to a job as men' in the supplementary questionnaire. The countries with high quality coefficients were, in this case, Portugal, Greece, and Switzerland. The lowest coefficients for this experiment were found in Estonia and the Czech Republic. To be able to separately study misspecifications in the categorization part of the model, we imposed no restrictions on the covariance matrix of the latent response variables at this stage. The estimation was done using the weighted least squares approach described by Flora \& Curran (2004)*1.

In the first analysis, all thresholds were constrained to be equal across the five countries. This yields a likelihood ratio statistic of 507 on 48 degrees of freedom. The country with the highest (128) contribution to this chi-square statistic is Portugal. When we examine the expected parameter changes, it also turns out that in this country these standardised values are very large with some values close to .9 while in other countries the highest obtained and exceptional value is .6. At the same time, there is nothing about this group that makes the power particularly high. There are a few very high power values of .97 for large expected changes, but the average power is .37. For some reason, the equality constraint on the Portuguese thresholds appears to be a particularly gross misspecification.

This misspecification is very likely due to a translation error. The intention of the experiment was to reverse the wording of the question in the second method. But in Portugal the reverse wording was not used, and the same version was presented as in the main questionnaire. The supplementary questions mean something else in Portugal and therefore it makes sense that the thresholds should differ from those found in the other countries. To prevent incomparability when the MTMM model is estimated, we omit Portugal from our further analyses and continue with four countries. We should note, however, that the resulting experiment does provide a good opportunity to examine the effect of a repetition on the threshold structure.

Continuing our analysis with four countries, the model where all thresholds are constrained to be equal yields a likelihood ratio of 351 and 36 degrees of freedom. We again approximate the power of the score test (modification index) to detect a standardised difference of at least .1, and examine the modification indices and expected parameter changes. 

Because there are many constrained parameters, the results are summarised in a plot rather than a table (figure \ref{fig:modindices}). The upper left quadrant of this plot shows parameters for which there is a low power of the score test, but which nevertheless exceed the critical value. These are all taken to be misspecifications. The upper right quadrant contains parameters for which the power is high and the score test significant. Only those parameters with a standardised expected change of .1 or higher—the two triangles—are taken to be misspecified. The lower right quadrant shows parameters for which the power was high but nevertheless the score test was not rejected. These are most likely not misspecified and can remain constrained to be equal across groups. The lower left quadrant, finally, contains parameters for which the power was low and the score test could not be rejected. Here no decision could be taken since it is not known whether the failure to reject is due to low power or because the model is correctly specified.

\begin{figure}\caption{The power and modification index of all thresholds which were constrained to be equal across the four countries. The points represent parameters, while the size of the point is determined by the size of the expected parameter change. The horizontal line is drawn at the chi-square quantile 6.63, i.e. the critical value for $\alpha=.01$. The vertical line imposes a criterion of ‘high power’ of .8.\label{fig:modindices}}
\end{figure}

Using the above criteria, it is clear that the equality model contains severe misspecifications2. We formulated a new model in which some thresholds were constrained to be equal, while others were freed to vary. However, we found that too many parameters were freed for Greece and some parameters could again be constrained to be equal: the expected parameter change which led us to free these parameters is an estimate, which need not equal the actual parameter change. For some thresholds the actual change was negligible (although still within a 95% confidence interval for the expected change) and we constrained these four parameters again. The resulting model has an approximate likelihood ratio of 2.8 on 2 degrees of freedom ($p=.24$)3. 

\begin{table}\centering\caption{\label{tab:women}}\begin{tabular}{lllrrr}
\hline
 &  &  & \multicolumn{3}{c}{`Women'} \\
 &  &  & CutDown & Respnsib. & MenRight\\
\hline
\multicolumn{2}{l}{Continuous analysis}\\
		   & $q$ & Greece & 0.84 & -0.81 & 0.84\\
 &  & Slovenia & 0.73 & -0.50 & 0.82\\
 & $q^2$ & Greece & 0.71 & 0.66 & 0.71\\
 &  & Slovenia & 0.54 & 0.25 & 0.68\\
\multicolumn{2}{l}{Categorical analysis}   &  &  &  & \\
 & $q$ & Greece & 0.71 & 0.59 & 0.69\\
 &  & Slovenia & 0.83 & 0.53 & 0.81\\
 & $q^2$ & Greece & 0.51 & 0.35 & 0.48\\
 &  & Slovenia & 0.69 & 0.29 & 0.65\\
 \multicolumn{2}{l}{Categorisation factor}   &  &  &  & \\
 &  & Greece & 1.4 & 1.9 & 1.5\\
 &  & Slovenia & 0.8 & 0.9 & 1.0\\
\hline
\end{tabular}\end{table}

\begin{table}\centering\caption{\label{tab:job}}\begin{tabular}{lllrrr}
\hline
  &    & & \multicolumn{3}{c}{`Job'} \\
 &      &   & Varied & Secure & Risky\\
\hline
\multicolumn{2}{l}{Continuous analysis    } &  &  &  & \\
 &   $q$ & Belgium & 0.94 & 0.94 & 0.96\\
 &    & Slovenia & 0.78 & 0.46 & 0.74\\
 &   $q^2$ & Belgium & 0.88 & 0.88 & 0.92\\
 &    & Slovenia & 0.61 & 0.21 & 0.55\\
\multicolumn{2}{l}{Categorical analysis  }   &  &  &  & \\
 &   $q$ & Belgium & 0.96 & 0.76 & 0.82\\
 &    & Slovenia & 0.71 & 0.54 & 0.82\\
 &   $q^2$ & Belgium & 0.92 & 0.58 & 0.66\\
 &    & Slovenia & 0.50 & 0.29 & 0.67\\
\multicolumn{2}{l}{Categorisation factor}     &  &  &  & \\
 &    & Belgium & 0.96 & 1.52 & 1.39\\
 &     & Slovenia & 1.22 & 0.72 & 0.82\\
\hline
\end{tabular}\end{table}

\begin{table}\centering\caption{\label{tab:doctors}}\begin{tabular}{lllrrr}

\hline
&&&\multicolumn{3}{c}{`Doctors'}\\
 &  &  & Truth & Equals & Discuss\\
\hline
\multicolumn{2}{l}{Continuous analysis   }&  &  &  & \\
 & $q$ & Denmark & 0.22 & 0.86 & 0.88\\
 &  & Estonia & 0.65 & 0.92 & 0.91\\
 & $q^2$ & Denmark & 0.05 & 0.74 & 0.77\\
 &  & Estonia & 0.42 & 0.85 & 0.83\\
\multicolumn{2}{l}{Categorical analysis  } &  &  &  & \\
 & $q$ & Denmark & 0.35 & 0.91 & 0.90\\
 &  & Estonia & 0.87 & 0.89 & 0.87\\
 & $q^2$ & Denmark & 0.12 & 0.83 & 0.82\\
 &  & Estonia & 0.75 & 0.79 & 0.75\\
\multicolumn{2}{l}{Categorisation factor}   &  &  &  & \\
 &  & Denmark & 0.41 & 0.89 & 0.94\\
 &  & Estonia & 0.56 & 1.07 & 1.10\\
\hline
\end{tabular}\end{table}

\begin{table}\centering\caption{\label{tab:efficacy}}\begin{tabular}{lllrrr}
\hline
 &  &  &  & `Efficacy' & \\
	   &  &  & Complex & Active & Mind\\
	   \hline
 \multicolumn{2}{l}{Continuous analysis}\\
	 & $q$ & Switzerland & 0.70 & -0.90 & 0.71\\
 &  & Denmark & 0.88 & -0.91 & -0.89\\
 & $q^2$ & Switzerland & 0.49 & 0.81 & 0.50\\
 &  & Denmark & 0.77 & 0.83 & 0.79\\
\multicolumn{2}{l}{Categorical analysis}   &  &  &  & \\
 & $q$ & Switzerland & 0.79 & 0.97 & 0.79\\
 &  & Denmark & 0.79 & 0.84 & 0.80\\
 & $q^2$ & Switzerland & 0.62 & 0.94 & 0.62\\
 &  & Denmark & 0.63 & 0.70 & 0.63\\
\multicolumn{2}{l}{Categorisation factor}    &  &  & \\
 &  & Switzerland & 0.79 & 0.86 & 0.81\\
 &  & Denmark & 1.23 & 1.18 & 1.25\\

\hline
\end{tabular}\end{table}


\begin{table}\centering\caption{\label{tab:meta}}
\begin{minipage}[ht]{.73\textwidth}
\begin{tabular}{llrrrr}
\hline
 &  & Estimate & S.E. & lower & upper\\
 \hline
 & (Intercept) & -0.04 & 0.22 & -0.49 & 0.40\\
\multicolumn{2}{l}{\textit{Topic}}&  &  &  & \\
 & Doctors & (reference category) &  &  & \\
 & Efficacy & 0.14 & 0.12 & -0.11 & 0.39\\
 & Job & 0.20 & 0.19 & -0.18 & 0.57\\
 & Women & 0.45 & 0.17 & 0.11 & 0.79\\
\multicolumn{2}{l}{\textit{Country  } }&  &  &  & \\
 & Belgium & (reference category) &  &  & \\
 & Slovenia & 0.09 & 0.10 & -0.11 & 0.29\\
 & Czech Republic & 0.28 & 0.15 & -0.02 & 0.59\\
 & Switzerland & 0.31 & 0.15 & 0.01 & 0.61\\
 & Greece & 0.32 & 0.15 & 0.01 & 0.63\\
 & Denmark & 0.33 & 0.17 & -0.02 & 0.67\\
 & Estonia & 0.53 & 0.19 & 0.15 & 0.92\\
\multicolumn{2}{l}{\textit{Scale   }}&  &  &  & \\
 & Agree-disagree & (reference category) &  &  & \\
 & Direct & 0.12 & 0.09 & -0.07 & 0.30\\
 & True-false & 0.42 & 0.14 & 0.13 & 0.70\\
\multicolumn{2}{l}{\textit{Scale position}   }&  &  &  & \\
 & Negative & (reference category) &  &  & \\
 & `Usually' & 0.39 & 0.15 & 0.09 & 0.69\\
 & `Rarely' & 0.41 & 0.15 & 0.11 & 0.71\\
 & Positive & 0.48 & 0.07 & 0.34 & 0.63\\
\hline
\end{tabular}

Multiple R-Squared: 0.55; Adjusted R-squared: 0.44; F-test for factor sums of squares: 
\begin{quote}Topic: $p=.16$; Country: $p=.17$; Scale: $p=.02$; Position: $p<.00001$.\end{quote}
\end{minipage}
\end{table}


\section{Discussion and conclusion}

interpret meta

advice

future research.

\newpage
\bibliography{quality}

\end{document}
